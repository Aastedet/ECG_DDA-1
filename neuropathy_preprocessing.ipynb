{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PandaPowell/ECG_DDA/blob/master/neuropathy_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yiS6O6yISgW"
      },
      "source": [
        "# Processing ECG data in Python\n",
        "\n",
        "\n",
        "1.   Setup\n",
        "  *   Install and import packages\n",
        "  *   Mount Google Drive and sync to Git repository\n",
        "  *   Copy the filtered ECG files from previous R workflow to Google Drive\n",
        "\n",
        "\n",
        "2.   Processing ECG data\n",
        "  *  Remove year string from ECG header files\n",
        "  *  Read signal channels and make sure ECG leads are in channels 1 & 2.\n",
        "  *  Split ECG data into 10 second snippets, and export plots as images\n",
        "\n",
        "3.   Next up:\n",
        "   * Script to train neuropathy classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huDCGyGpYR-i"
      },
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paLv8DbXKZ8z"
      },
      "source": [
        "### Install and import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "id": "Lm5wc13ZTKPj",
        "outputId": "2e79ff8c-316a-474b-b963-8af8afc42547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wfdb\n",
            "  Downloading wfdb-3.4.1-py3-none-any.whl (137 kB)\n",
            "\u001b[K     |████████████████████████████████| 137 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting matplotlib>=3.3.4\n",
            "  Downloading matplotlib-3.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 41.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.7/dist-packages (from wfdb) (2.23.0)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.3.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.7/dist-packages (from wfdb) (1.21.6)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->wfdb) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->wfdb) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->wfdb) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->wfdb) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->wfdb) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.4->wfdb) (1.4.2)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
            "\u001b[K     |████████████████████████████████| 930 kB 42.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.3.4->wfdb) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->wfdb) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.4->wfdb) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.8.1->wfdb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.8.1->wfdb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.8.1->wfdb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.8.1->wfdb) (2021.10.8)\n",
            "Installing collected packages: fonttools, matplotlib, wfdb\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed fonttools-4.33.3 matplotlib-3.5.2 wfdb-3.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.5.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (4.33.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# Installs\n",
        "!pip install wfdb\n",
        "!pip install -U matplotlib\n",
        "\n",
        "# Imports\n",
        "from IPython.display import display\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import posixpath\n",
        "import wfdb\n",
        "import pandas as pd\n",
        "from scipy import signal\n",
        "import re\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "likvwR_8KeFT"
      },
      "source": [
        "### Mount Google Drive and sync to Git repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnRS891LX1NQ",
        "outputId": "d0c51c19-0613-4618-9000-b8c90333d392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/ecg_data\n",
            "/content/ecg_data/MyDrive/ecg_ai\n"
          ]
        }
      ],
      "source": [
        "## Mount google drive\n",
        "drive.mount('/content/ecg_data')\n",
        "\n",
        "# Clone git repo (uncomment if not already cloned)\n",
        "%cd '/content/ecg_data/MyDrive/ecg_ai/'\n",
        "#! git clone https://github.com/PandaPowell/ECG_DDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zoO94lwk6p3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad665fa9-f2c5-4d8a-ecde-353836d7fd67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ecg_data/MyDrive/ecg_ai/ECG_DDA\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "# Pull updates:\n",
        "%cd '/content/ecg_data/MyDrive/ecg_ai/ECG_DDA'\n",
        "! git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8qomEb4KtuK"
      },
      "source": [
        "### Copy the filtered ECG files from previous R workflow to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67g6yyBmQutF"
      },
      "source": [
        "  * If you've previously run or knitted the `readme.Rmd` script from the *R* session, you can copy the contents of your local `/ecg_data/` folder to the corresponding folder in the repo cloned to your mounted google drive (in this case `/content/ecg_data/MyDrive/ecg_ai/ECG_DDA/ecg_data/`).\n",
        "  * If you haven't run the *R* preprocessing script, you can grab the preprocessed ECG data from the [`/ecg_data/` folder here](https://drive.google.com/drive/folders/17AX33KuzP2nZwCQ9sWErY_0bSGI-ON1R?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4v0zpK9M9OL"
      },
      "source": [
        "## 2. Processing ECG data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge7havT0NCMD"
      },
      "source": [
        "### Remove year string from ECG header files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkFWkCRwNJyT"
      },
      "source": [
        "Can't read data otherwise (feature or bug?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRanatQY3q2o"
      },
      "outputs": [],
      "source": [
        "# Function (Credit to Anders Askeland)\n",
        "def remove_year_from_hea(filename: str) -> None:\n",
        "    '''\n",
        "    Removes year from header file in wfdb (.hea) on line 1. Run before reading file with wfdb functions. Does not overwrite original date, wherein the function will rename the original file to: '***_original.hea'.\n",
        "\n",
        "    PS: Very rudimentary function: will always remove 4 digit strings (regex based) if they appear to the left of newline char (\\n).\n",
        "\n",
        "    Args:\n",
        "        filepath to .hea file (without .hea extension)\n",
        "    \n",
        "    Attributes:\n",
        "        None\n",
        "    '''\n",
        "    \n",
        "    # Rewrite hea file\n",
        "    with open(filename + \".hea\", \"r\", encoding='utf-8') as f:\n",
        "        \n",
        "        # Read lines\n",
        "        text = f.readlines()\n",
        "\n",
        "        # Modify line 1 (with regex)\n",
        "        pattern = '\\s\\d{4}(?=(\\\\n))'\n",
        "        if not re.search(pattern, text[0]):\n",
        "            print(\"Year is already removed. Doing nothing.\")\n",
        "            return(1)\n",
        "        else:\n",
        "            print(\"Removing year from line 1\")\n",
        "            modified_line = re.sub(pattern, '', text[0])\n",
        "            text[0] = modified_line\n",
        "    \n",
        "    # Rename original file (don't need)\n",
        "    # os.rename(filename + '.hea', filename + '_original.hea')\n",
        "    \n",
        "    # Create new file\n",
        "    with open(filename + \".hea\", \"w\", encoding='utf-8') as f:\n",
        "        f.writelines(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ybm-CZ557qu"
      },
      "outputs": [],
      "source": [
        "# Apply function to all .hea files:\n",
        "directory = '/content/ecg_data/MyDrive/ecg_ai/ECG_DDA/ecg_data/'\n",
        "\n",
        "hea_list = list()\n",
        "\n",
        "for root, directories, filenames in os.walk(directory):\n",
        "  for filename in filenames:\n",
        "    if filename.endswith('.hea'):\n",
        "      hea_list += [os.path.join(root, filename) for file in filenames]\n",
        "\n",
        "hea_list_2 = list()\n",
        "\n",
        "# Remove filename endings and feed to function:\n",
        "for filename in hea_list:\n",
        "    name = filename.split('.')[0]\n",
        "    hea_list_2.append(name)\n",
        "\n",
        "for files in hea_list_2:\n",
        "  remove_year_from_hea(files)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXHEnBtJOgQL"
      },
      "source": [
        "### Read signal channels\n",
        "Make sure ECG leads are in channels 1 & 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vQlu4tebbaE"
      },
      "source": [
        "Everything is in the right place at the start of monitoring. While that's a good start, wired connections will be prone to the patient unplugging and replugging them to wrong channels in a real-world setting. We'll ignore this issue, as we see no feasible way to address it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86tPZf1vVgA0"
      },
      "outputs": [],
      "source": [
        "ecg_root = '/content/ecg_data/MyDrive/ecg_ai/ECG_DDA/ecg_data/'\n",
        "\n",
        "lst = list()\n",
        "for (ecg_root, dirnames, filenames) in os.walk(ecg_root):\n",
        "  for filename in filenames:\n",
        "    if filename.endswith(('.hea','.dat')):\n",
        "      lst += [os.path.join(ecg_root, file) for file in filenames]\n",
        "\n",
        "lst2 = []\n",
        "\n",
        "for filename in lst:\n",
        "    name = filename.split('.')[0]\n",
        "    lst2.append(name)\n",
        "\n",
        "# Get unique list, sorted for keep indices reproducible in case of crashes\n",
        "lst3 = sorted(list(set(lst2))) \n",
        "\n",
        "# Remove image files (in case some splitting to images has been already done)\n",
        "lst3 = [x for x in lst3 if x.endswith('ECG')]\n",
        "\n",
        "# Manually check quality of ECGS\n",
        "# Split into chunks of 10 to avoid running out of memory:\n",
        "# for filename in lst3[0:9]:\n",
        "#     print(filename)\n",
        "#     # load a record using the 'rdrecord' function\n",
        "#     record = wfdb.rdrecord(filename)    \n",
        "#     sig1 = pd.DataFrame(record.p_signal)\n",
        "#     sig1.columns = ['ecg_0' , 'ecg_1', 'sensor_0' , 'sensor_1', 'emg_0', 'emg_1', 'accelerometer_0', 'accelerometer_1']\n",
        "#     figure, axis = plt.subplots(2, 2, figsize=(25, 8))\n",
        "#     L = record.fs*10\n",
        "    \n",
        "#     axis[0, 0].plot(sig1.iloc[1:L,0])\n",
        "#     axis[0, 0].set_title(record.record_name)\n",
        "#     axis[0, 1].plot(sig1.iloc[1:L,1])\n",
        "#     axis[0, 1].set_title(record.record_name)\n",
        "#     axis[1, 0].plot(sig1.iloc[2:L,2])\n",
        "#     axis[1, 0].set_title(record.record_name)\n",
        "#     axis[1, 1].plot(sig1.iloc[3:L,3]) \n",
        "#     axis[1, 1].set_title(record.record_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSGiA_imcNpq"
      },
      "source": [
        "### Split ECG data into 10 second snippets, and export plots as images\n",
        "While we lose some precision in the data with this approach (depending on image resolution) and lose information contained in the header, this loss is beneficial as it prevents against over-fitting, and the aim is to be able to classify raw ECGs without any additional data.\n",
        "\n",
        "If Colab throws an error, you may need to restart the run-time and re-run the `Install and import packages` & `Read signal channels` chunks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee0Y_H6RGvI8"
      },
      "source": [
        "#### Sample balance:\n",
        "Sample length varies a lot: 47 of the 60 individuals produce less than 200 10-second snippets, but 7 individuals produce more than 5000.\n",
        "\n",
        "To balance the dataset, each individual only contributes the first 2000 seconds (33 minutes, 200 snippets). Hopefully the wires remain in their right place for most of this interval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmA2JCbE_EaZ"
      },
      "outputs": [],
      "source": [
        "# Plot 10 second ECGs for all individuals, to check sample lengths\n",
        "# Length varies a lot: 47 of the 60 individuals produce less than 200 10-second snippets,\n",
        "# but 7 individuals produce more than 5000:\n",
        "\n",
        "for index, filename in enumerate(lst3):\n",
        "    \n",
        "    print('filename: ', filename)\n",
        "    print('index: ', index)\n",
        "    \n",
        "    # load a record using the 'rdrecord' function\n",
        "    record = wfdb.rdrecord(filename)\n",
        "    \n",
        "    sig1 = pd.DataFrame(record.p_signal)\n",
        "    \n",
        "    # record time\n",
        "    print('10-sec snippets: ', sig1.shape[0] / record.fs/ 10, '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Export signal 1: lead V1/V2"
      ],
      "metadata": {
        "id": "4OnrRlwfv8ad"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzBYFd2Aaa_A"
      },
      "outputs": [],
      "source": [
        "# Plot first 200 10 second ECGs for all individuals, both ECG signals\n",
        "\n",
        "### Signal 1 ###\n",
        "for index, filename in enumerate(lst3[44:]):\n",
        "    \n",
        "    \n",
        "    clear_output(wait=True)\n",
        "    print('index: ', index)\n",
        "    print(filename)\n",
        "    \n",
        "    # load a record using the 'rdrecord' function\n",
        "    record = wfdb.rdrecord(filename)\n",
        "    \n",
        "    sig1 = pd.DataFrame(record.p_signal)\n",
        "    \n",
        "    # record time\n",
        "    print('How many 10 second measurement intervals:', sig1.shape[0] / record.fs/ 10)\n",
        "    \n",
        "    # Define 10 sec interval via record freq times 10\n",
        "    ten = record.fs*10\n",
        "    # Create sequence of intervals \n",
        "    ten_int = np.arange(0, sig1.shape[0], ten)\n",
        "    \n",
        "    # Limit to first 200\n",
        "    if (len(ten_int) > 200):\n",
        "        len_sig = 200\n",
        "    else:\n",
        "        len_sig = len(ten_int)\n",
        "        \n",
        "    print(len_sig)\n",
        "        \n",
        "    for x in range(1,len_sig):\n",
        "        print(x)\n",
        "        plt.figure()\n",
        "        plt.plot(sig1.iloc[ten_int[x-1]:ten_int[x],0])\n",
        "        plt.ylabel('V1/V2')\n",
        "        plt.savefig(filename + '_signal1_' + str(x) + '.png', dpi=500)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY_JZcsi_MMo"
      },
      "outputs": [],
      "source": [
        "# Sometimes you go out of memory and crash, just restart the above cell from the last index in the output:\n",
        "# E.g. if last output was:\n",
        "# Index: 23\n",
        "# run loop on\n",
        "lst3[23:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Export signal 2: lead V5/V6"
      ],
      "metadata": {
        "id": "-7XKlTHhwMhF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f9g4oa_2Ie1"
      },
      "outputs": [],
      "source": [
        "### Signal 2 ###\n",
        "for index, filename in enumerate(lst3):\n",
        "    \n",
        "    clear_output(wait=True)\n",
        "    print('index: ', index)\n",
        "    print(filename)\n",
        "    \n",
        "    # load a record using the 'rdrecord' function\n",
        "    record = wfdb.rdrecord(filename)\n",
        "    \n",
        "    sig1 = pd.DataFrame(record.p_signal)\n",
        "    \n",
        "    # record time\n",
        "    print('How many 10 second measurement intervals:', sig1.shape[0] / record.fs/ 10)\n",
        "    \n",
        "    # Define 10 sec interval via record freq times 10\n",
        "    ten = record.fs*10\n",
        "    # Create sequence of intervals \n",
        "    ten_int = np.arange(0, sig1.shape[0], ten)\n",
        "    \n",
        "    # Limit to first 200\n",
        "    if (len(ten_int) > 200):\n",
        "        len_sig = 200\n",
        "    else:\n",
        "        len_sig = len(ten_int)\n",
        "        \n",
        "    print(len_sig)\n",
        "        \n",
        "    for x in range(1,len_sig):\n",
        "        print(x)\n",
        "        plt.figure()\n",
        "        plt.plot(sig1.iloc[ten_int[x-1]:ten_int[x],1])\n",
        "        plt.ylabel('V5/V6')\n",
        "        plt.savefig(filename + '_signal2_' + str(x) + '.png', dpi=500)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Next up: Training a model\n",
        "Model training is done in the [next notebook](https://colab.research.google.com/drive/1_b-j3hDzYTYbbqGdyUnoaGiPZyRMbcJE?usp=sharing)"
      ],
      "metadata": {
        "id": "Udevv8IiwPvF"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "neuropathy_preprocessing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHFp9faLPzy0aU/7ZMJ0Ul",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}